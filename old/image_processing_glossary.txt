# check the word type (v vs n vs adj etc, only use n)# source https://jeffreymorgan.io/articles/image-processing-glossary/
Addition: A point process that blends the values of corresponding pixels in two input images. A single parameter controls which input image dominates the output image.
Area Processes: A category of image-processing techniques that calculate the value of each output-image pixel from the corresponding input-image pixel and its neighbors. Examples include halftoning, sharpening and median filtering.
Aspect Ratio: The ratio of the width of an image to its height. Examples include 4:3, the aspect ratio of a standard TV, and 16:9, the aspect ratio of a widescreen TV.
Average Greyscale: The shade of grey produced by adding the brightnesses of the RGB components of a colour pixel and dividing by three.
Backward Mapping: The technique geometric processes use to calculate output-image pixel values from input-image pixel values. Backward-mapping processes start with a pixel in the output image, find the corresponding pixel in the input image, calculate a new pixel value, and assign the new value to the output-image pixel.
Bayer Filter: Enables a CCD to capture colour by covering 2x2 blocks of CCD-sensor elements with one red, one blue and two green filters, which makes colour CCDs more sensitive to the green wavelengths of light, just like our eyes.
Bi-linear Interpolation: A method of calculating the value of a pixel with fractional co-ordinates that lies in between a 2x2 neighborhood of pixels.
Bitmap Image: An image composed of black and white pixels.
Blurring: An area process that produces an effect similar to an out-of-focus photograph. Blurring removes the detail in an image by making each pixel more like its neighbors.
Bounding Box: The smallest rectangle that encloses a shape so that each of the four sides touches an extremity of the shape.
Brightness: Determines the intensity of the colour presented by a pixel in a colour image, or the shade of grey presented by a pixel in a greyscale image.
Brightness Transformation: A point process that maps input brightnesses onto output brightnesses with a linear or non-linear mathematical function.# Capture: The process of measuring and visualizing physical phenomena such as visible and non-visible electromagnetic radiation. Examples include taking a photograph and scanning a document.
CCD: A charge-couple device is an imaging sensor that contains a rectangular grid of light-sensitive capacitors. Each capacitor accumulates a charge proportional to the brightness of the light it detects; the brighter the light, the higher the charge.
Closing: A morphological operation produced by following a dilation by an erosion. Often used for filling holes in bitmap images.
Colour Model: Determines how the colour in a digital image is represented numerically. Examples include the RGB and HSB colour models.
Composition: A point process that overlays the pixels of a foreground input image onto the pixels of a background input image.
Contrast: The difference between the lightest and darkest regions of an image.
Contrast Expansion: An image-processing technique that re-distributes the brightness in an image to eliminate regions that are either too dark or too light. Examples include basic and ends-in contrast expansion.
Convolution: A method of calculating the new value of a central pixel in a neighborhood by multiplying each pixel in the neighborhood by a corresponding weight; the new value of the central pixel is the sum of the multiplications.
Corrupted Pixel: A pixel value altered by noise.
Cropping: A geometric process that reduces the size of an image by discarding the pixels outside a specified region called the crop selection.
Diagonal Axis: The line that runs from the top-left corner of an image to the bottom-right corner, or from the top-right corner to the bottom-left corner.
Digital Camera: An imaging device that focuses visible light onto a CCD.
Digital Image: An image captured by an imaging device and represented in a computer as a rectangular grid of pixels.
Dilation: A morphological operation that increases the size of objects in an image by adding a layer of foreground pixels around each object.
Edge: Edges mark the boundaries between the objects in a scene. A large change in pixel brightness over a small number of pixels often indicates the presence of an edge.
Edge Detector: An image-processing routine that flags the large changes in pixel brightness that indicate potential edges. Edge detectors often visualize their results in edge maps. Examples include the Sobel, Prewitt, Kirsch and Laplacian edge detectors.
Edge Direction: The angle that specifies the direction of an edge. The angle is perpendicular to the direction of the large change in brightness that indicates the edge.
Edge Magnitude: A number that represents how confident an edge detector is that it has found an edge in an image.
Edge Map: A greyscale output image that visualizes the magnitude of the edge found at each pixel in an input image; the greater the magnitude, the brighter the corresponding edge-map pixel. Thresholding an edge map highlights the strongest edges.
Edge Mask: A set of convolution weights that highlight the size and direction of the edges in an image.
Electromagnetic Spectrum: The complete range of electromagnetic radiation from short wavelength gamma radiation to long wavelength radio waves.
Erosion: A morphological operation that decreases the size of objects in an image by removing a layer of foreground pixels around each object. Often used for removing projections and blobs in bitmap images.
Flipping: A geometric process that swaps the pixels in an image across the horizontal, vertical and diagonal axes.
Forward Mapping: The technique point and area processes use to calculate output-image pixel values from input-image pixel values. Forward-mapping processes start with a pixel in the input image, calculate a new pixel value, and assign the new value to the corresponding pixel in the output image.
Frame Averaging: A point process that removes noise from a series of input images taken of the same subject. Each output-image pixel value is the average of the corresponding input-image pixel values.
Gaussian Noise: A form of image noise that adds small positive and negative deviations to the pixels in an image, often caused by the random variations between the elements of a CCD sensor. Plotting the number of occurrences of each deviation on a histogram produces the bell-shaped curve of the normal distribution, which is also called the Gaussian distribution.
Geometric Process: A category of image-processing techniques that change the size and shape of an image rather than its contents. Examples include cropping, scaling and rotation.
Greyscale Image: An image composed of pixels that present shades of grey.
Halftoning: An area process that simulates shades of grey in bitmap images with patterns of bitmap pixels. The density of each 2x2-pixel pattern depends on the ratio of black to white bitmap pixels.
Highlights: The range of pixel brightnesses that represent the lighter regions of an image.
High-key Image: An image that represents a naturally light subject.
High-contrast Image: An image with large numbers of pixels in the shadows and highlights.
High Frequency: The high frequency information in an image is represented by large changes in pixel brightness over a small number of pixels.
High-pass Filter: A filter that preserves or amplifies the high frequency information in an image. Sharpening is implemented by a high pass filter.
Histogram: The histogram of an image visualizes the distribution of the brightness in the image by plotting the number of occurrences of each brightness.
Histogram Equalization: An image-processing technique that reveals detail hidden in images with a poorly-distributed range of brightnesses.
Horizontal Axis: The line that runs through the centre of an image from the left of the image to the right.
HSB: A colour model that represents each colour with three numbers that specify the hue (H), the saturation (S) and the brightness (B) of the colour.
Hue: The colour in the HSB colour model.# Image: An image records a visual snapshot of the world around us.# Image Processing: The field of computer science that develops techniques for enhancing digital images to make them more enjoyable to look at, and easier to analyze by computers as well as humans.
Imaging Device: A piece of equipment that captures an image. Examples include digital cameras, side-scan sonar systems and scanning electron microscopes.
Impulse Noise: Also called salt and pepper noise, impulse noise introduces very light (salt) and very dark (pepper) pixels that stand out from their neighbors.
Interpolation: A method of creating new pixel values from existing pixel values. Examples include nearest-neighbor and bi-linear interpolation.# Input Image: The image transformed by an image-processing routine.
Inversion: A point process that produces an effect similar to photographic negatives: dark pixels become light and light pixels become dark.
Kernel: A rectangular grid of convolution weights.
Line Edge: A line chain of pixels that separates a region of light pixels from a region of dark pixels.
Linear Brightness Transformation: A category of brightness transformations that lighten and darken images using mathematical functions with curved graphs.
Look-up Table: A data structure that minimizes the number of calculations required to process an image with a point process. The brightness of each output-image pixel is found in a LUT at the entry indexed by the brightness of the corresponding input-image pixel.
LUT: A data structure that minimizes the number of calculations required to process an image with a point process. The brightness of each output-image pixel is found in a LUT at the entry indexed by the brightness of the corresponding input-image pixel.
Low-contrast Image: An image that uses only a small range of the available brightness. Low-contrast images are mostly dark, mostly dull or mostly light.
Low-key Image: An image that represents a naturally dark subject.
Low Frequency: The low frequency information in an image is represented by small changes in pixel brightness over a small number of pixels.
Low-pass Filter: A filter that discards or attenuates the high frequency information in an image and preserves the low frequency information. Removing the high frequency information from an image removes the detail and blurs the image. Blurring is implemented by a low pass filter.
Median Filtering: An area process that removes noise by replacing the central pixel in a neighborhood with the median pixel value of the neighborhood.
Mid-tones: The range of pixel brightnesses that represent the regions of an image in between the shadows and highlights.
Morphological Operation: A category of image-processing techniques that operate on the structure of the objects in an image.
Noise: Unwanted changes to the values of the pixels in an image, often introduced by the imaging device during capture. Examples include impulse noise and Gaussian noise.
Nearest-neighbor Interpolation: A method of creating values for pixels with fractional co-ordinates that duplicates the value of the pixel with integer co-ordinates nearest to the fractional co-ordinates.
Neighborhood Averaging: An area process that removes noise by replacing the central pixel in a neighborhood with the average pixel value of the neighborhood.
Non-linear Brightness Transformation: A category of brightness transformations that change the brightness of an image using mathematical functions with straight-line graphs. Examples include inversion and posterization.
Non-primary Colour: A colour created by mixing the red, green and blue primary colours of the RGB colour model.
NTSC Greyscale: A shade of grey produced by multiplying the brightnesses of the RGB components of a colour pixel by a set of weights that emphasize the green component. Named after the committee that oversees US television.
Opening: A morphological operation produced by following an erosion by a dilation. Often used for filling holes in bitmap images.
Outlying Pixel: A pixel with an extreme brightness that is much higher or lower than the brightnesses of the other pixels in the image.# Output Image: An image that contains the results of applying an image-processing routine to an image.
Photo Restoration: The application of a series of image-processing routines to enhance a damaged photograph.
Pixel: A square unit of visual information that represents a tiny part of a digital image.
Pixel Depth: The number of colours or shades of grey a pixel can present. Bitmap pixels have depth two, typical greyscale pixels have depth 256, and typical colour pixels have depth 16,777,216.
Pixel Neighborhood: A region of pixels processed by an area process. Typical neighborhood dimensions are 3x3 pixels and 5x5 pixels.
Point Processes: A category of image-processing techniques that calculate the value of each output-image pixel from the value of the corresponding input-image pixel. Examples include inversion and pseudo-colour.
Posterization: A linear brightness transformation that reduces the number of brightnesses in an image.
Pseudo-colour: A point process that divides the range of brightness in a greyscale input image into groups and assigns each group a colour. Each output-image pixel is assigned the colour that represents the group into which falls the brightness of the corresponding input-image pixel.
Potential Edge: Edge detectors flag all large changes in pixel brightness over a small number of pixels as a potential edge. An edge-analysis system then decides whether the change in brightness represents the border of an object—a real edge—or some other feature of the object, such as its texture.
Primary Colours: The colours red, green and blue from which all other colours in the RGB colour model are mixed.
Quantization: The calculation that maps the fractional measurements made by imaging devices onto proportional integer pixel brightnesses.
Ramp Edge: A region of pixels that separates a region of light pixels from a region of dark pixels. The pixels in the region change gradually from light to dark.
Raw Colour: The colour of the pixels in an image captured by a colour CCD before the two unknown RGB-component brightnesses of each pixel have been interpolated from the known brightnesses of the corresponding components of neighboring pixels.
Resolution: The number of pixels available to represent the details of the subject of a digital image.
RGB: A colour model that represents each colour with three numbers that specify the amounts of red (R), green (G) and blue (B) that produce the colour.
RGB Colour Cube: Visualizes the amounts of red, green and blue required to produce each colour in the RGB colour model as a point in a cube at co-ordinates (x, y, z).
Roof Edge: A region of pixels that separates a region of light pixels from a region of dark pixels. The pixels in a roof edge increase in brightness to their maximum at the apex of the roof and then decrease to meet the region of pixels on the other side of the edge.
Rotation: A geometric process that turns an image about its centre by a specified angle.
Rotation Hole: An output-image pixel not assigned a value when the input image is rotated with forward mapping.
Row-Column Co-ordinates: The pair of numbers that locate a pixel in the rows and columns of the rectangular grid of pixels that represent a digital image.
Sampling: The process of mapping a continuous quantity of electromagnetic radiation, such as light or X-rays falling on a sensor, onto a discrete, rectangular grid of pixels.
Saturation: The component of the HSB colour model that controls the amount of white mixed into the hue.
Scale Factor: A fractional number that controls whether a scaling process enlarges or reduces an image. Scale factors between zero and one reduce images; scale factors greater than one enlarge images.
Scaling: A geometric process that changes the size of an image.
Scanner: An imaging device that focuses light reflected from a document onto a CCD that moves across and down the document.
Scanning Electron Microscope: An imaging device that uses electrons to capture images of microscopic objects. A SEM fires a beam of electrons at the surface of the sample and counts the number of electrons dislodged from the surface by the beam; the greater the number of dislodged electrons, the brighter the corresponding point in the image.
Sequential-index Co-ordinate: The number that locates a pixel in an image when the pixels in the image are laid end to end in a sequence.
Shadows: The range of pixel brightnesses that represent the darker regions of an image.
Sharpening: An area process that emphasizes the detail in an image.
Side-scan Sonar System: An imaging device that uses sound waves to capture images of underwater objects. Side-scan sonar systems measure the strength of the acoustic reflections of sound waves directed at the sea bed; the stronger the acoustic reflection, the brighter the corresponding pixel in the image.
Step Edge: The ideal edge shape characterized by a large, immediate change in pixel brightness from a region of light pixels to a region of dark pixels.
Structuring Element: The rectangular grid of binary values used by morphological operations to assign a new value to a pixel in a bitmap image.
Subtraction: A point process that identifies the pixels that differ between two input images.
Thresholding: A point process that produces a bitmap version of a greyscale image. Black bitmap pixels represent greyscale pixels darker than a threshold brightness; white bitmap pixels represent greyscale pixels lighter than the threshold.
Thermal Camera: An imaging device that measures the amount of infra-red light emitted by the subject of the image. Hotter objects emit more infra-red light, which show up as the brighter regions of a thermal image.
Thermal Image: A greyscale image captured by a thermal camera. Often enhanced with pseudo-colour to assign the same colour to regions of pixels that represent similar temperatures.
Vertical Axis: The line that runs through the centre of an image from the top of the image to the bottom.# source http://www-g.eng.cam.ac.uk/rms/glossary.html
Aliasing: the problem of using too coarse a grid to sample a continuous function. Fluctuations on a scale finer than that of the grid are distinguishable from coarser detail. The artificial low spatial frequency components cannot be separated from real structure in the original image. If digitised grid intensities are then displayed as discrete pixels, high frequency (sharp) information may appear to be present in the digitised image, particularly along smooth edges which appear "stairstepped" or "jagged". Special "anti-aliasing" techniques can be used to suppress the jagged appearance of the display but these do not correct for any undersampling during the acquisition of the data.
Analogue: an analogue signal is capable of having a continuously varying value. Contrast with digital.
Analogue to digital converter: a device that senses an analogue signal and converts it into a proportional representation in digital form.
Artefact(ing): Misinterpreted information from a JPEG or compressed image. Colour faults or line faults that have a visible negative impact on the image.
Bi-level image: another term for a binary image.
Binary (sometimes Bit) image: an image where pixel intensities take only two possible values, either zero or a specific non-zero value (typically unity or full-scale).
Binary images take much less space to store in the image memory of the computer or on a disc since each pixel can be represented by one bit (see bit), and they are convenient for making measurements, e.g. area or perimeter of a feature. Often, a binary image may be shown as white (for 1) and black (for 0).
Binary image operators: calculations on a binary image. These include:-
Erosion: the removal of a layer of pixels around a feature. Small features may be totally removed, separated into their components.
Dilation: The reverse of erosion; adding a layer of pixels around a feature. Features which are fragmented can be rejoined.
Opening: Erosion followed by dilation may separate features which were linked by a narrow neck. Small features can be lost, whilst leaving the size of resultant features approximately unchanged.
Closing: Dilation followed by erosion can be used to fill in small holes or cracks. In order to remove all irregularities, both protuberances and holes, opening followed by closing can be performed.
Skeletonisation: Similar to erosion, except that the process stops when the feature is only one pixel wide. A broad line would be reduced a thin line, although the irregularities in the original line may produce many "whiskers" branching off the resultant thin line.
Bit: the smallest unit of digital information, having the value "0" or "1" only. The term is a contraction from ‘binary’ and ‘digit’. A binary image is a "1-bit" image, whilst a grey image may be stored as a "6-bit" image since a traditional tube TV camera can distinguish about 64 grey values (26 = 64). Note that modern CCD cameras (see below) can distinguish 1000 or more grey values.
Bit Depth: this refers to the grey scale (or colour scale) adopted for an individual pixel. A pixel with 8 bits per colour gives a 24 bit image. (8 bits x 3 colours is 24 bits.)
Bitmap: the method of storing information that maps an image pixel, bit by bit. There are many bitmapped file formats, .bmp, .pcx, .pict, .pict-2, tiff, .tif, .gif (89a), and so on. Most image files are bit mapped. This type of file often gives rise to the effect known as ‘jaggies’: when examined closely the line of pixels that create edges can be seen. Bitmap images are used by all computers. For example, the desktop or screen information for MS Windows machines uses .bmp files, while the Macintosh uses .pict files.
Blob: a term sometimes used to describe a region of connected pixels of the same type.
Byte: a unit of digital information, consisting of eight bits. A byte can have 28 or 256 different combinations of bits. Much computer hardware is geared to handling information in bytes. Coincidentally, in many applications, a byte is sufficient to represent the information about the grey level of a pixel.
Kilobyte: 210 or 1024 bytes, written KB.
Megabyte: 220 bytes or 1024 kilobytes, written MB. Both terms are used to refer to size of files or media such as hard drives where capacities are too great to be expressed directly in bytes. Refers to amount of information in a file, or how much information can be contained on a Hard Drive or Disk.
CCD camera: a video camera containing a Charge-Coupled Device, which is a semiconductor light sensor in the form of an integrated circuit. CCDs are smaller, more robust, and offer better performance than older video cameras which make use of a vidicon tube as the sensor. In their normal condition, CCDs are greyscale devices. To create colour a colour pattern is laid down on the sensor pixels, using an RGBG colour mask (Red, Green, Blue, and Green). The extra Green is used to create contrast in the image. The CCD Pixels respond independently to coloured light and pass their electronic responses into a shift register for storage. CCDs are analogue sensors; digitising happens when the electronic signal from the shift register is passed to the input of an Analogue to Digital Converter (ADC). The ADC converts the analogue signal to a sequence of digital numbers.
Chrominance: the colour portion of a video signal.
Chain-code: a method of coding information about the position of the boundary of an object, in which the information held is is simply the direction in which one must move in order to reach the next pixel on the boundary. In many cases this is a very efficient way of encoding boundary information.
CMYK: Cyan, Magenta, Yellow, Black. These are the printed colours typically used to create colour prints. Most colour printers: Ink-Jet, Laser, Dye-Sublimation, Thermal, and Crayon printers: use these as their printer colours. This is one of the colour management problems for computers, since converting RGB files to CMYK files may cause unwanted colour shifts. When used by a printer, CMYK is also known as reflective color since it is printed on paper or reflective films.
Compression: techniques used by imaging devices and software to reduce image storage requirements without objectionably affecting the appearance of the image.
Digital: with discrete values (in contrast with analogue). Digital data can be handled without errors, whereas manipulation of analogue data will always entail some finite degree of error, however small.
Digitisation: conversion of analogue information to digital form. For example, the output of an SEM electron detector requires digitisation in both spatial and amplitude terms before it can be processed using digital computing methods.
Digitising tablet: a tablet connected to a computer or image analyser on which the features or interest in a specimen can be drawn using a hand-held cursor or electronic "pen". The x,y coordinates of the cursor are processed by the host computer and may be used to calculate the area, perimeter, centre or gravity, orientation, etc. of the feature.
DQE: detection quantum efficiency, i.e. "efficiency of recording quanta"
DQE = (S/N of recorded data)2 + (S/N "available" in original)
Dynamic range: the ratio between the brightest and dimmest grey level acceptable to an imaging system.
EPS: Encapsulated Postscript, a computer file standard set by Adobe for printers, which represents a mathematical definition of shapes, lines, color and space. This standard is one of the most accurate ways to define a font or image, but creates files of very considerable size. EPS files also add page description information to the files. Although forms of EPS are used on all computer, not all postscript files are the same, nor are they transferable between programs. EPSF is an IBM file type generally, EPSP is usually found on Macintosh, and there are many other variations of each type.
False colour (Pseudo colour): an artificial display where colours are used to represent different ranges of intensity. The choice of colours is often arbitrary so to this extent is "false". However, there may be genuine relationship between intensity and some physical parameter (e.g. atomic number), in which case "colour coding" is a more appropriate term. A grey image may be displayed in false colour to highlight particular features.
Feature: part of an image which can be isolated from the remainder by some means. For example, a "particle" can often be distinguished by having a generally brighter intensity than its surroundings. Separation of an image into features is referred to as "segmentation".
Filter: a device, method or program algorithm that separates signals or other data based upon certain specified criteria
Frame grabber: an input device that picks up an image from a video camera and digitises the analogue signal into a defined number of bits per pixel, and transmits it to some form of digital memory.
GIF: Graphic Interchange Format, originally used by CompuServe for storage of graphical images in lossless compressed form. This was developed for use with images of up to 256 colours or shades (up to 8 bits) and is effective with low-noise or graphical images. This format was widely used in the late 80s for image transfer. GIF 89 is the most recent GIF standard and allows multiple images within one file, selection of area for transparency as well as other features. The primary use of this format has been on the Internet. However, there has since been dispute over the ownership of the embedded compression technology, and other formats are now more widely used.
Grey image: often known as a grey scale image, or grey level image: an image in which the regions or points may take on a range of values or grey levels (distinguished from a binary image in which only two are allowed). To match a conventional 625-line TV camera a typical grey image consists of 512 lines with 512 pixels on each line, i.e. 262144 pixels.
Grey level: the amplitude or energy level associated with a region or point of an image.
Grey level histogram: in digital image processing, "histogram" refers to the distribution showing the number of pixels which have a particular intensity value.
Hue: the name of a colour such as red or blue. The hue of a colour is its dominant wavelength.
HSI: hue, saturation, intensity. An abbreviation for all of a colour's characteristics: hue (the pigment); the saturation (the amount of pigment); and intensity (the amount of white included). All colours can be defined by expressing these characteristics in percentages.
# Image: a two-dimensional representation of the response from some sensing device, responding typically but not necessarily to light or other radiation. The process of digitisation produces a digital image consisting of a table of numeric values which describe the relative positions and values of the original responses.
Image analysis: an operation or set of operations designed to yield a numerical or logical result from an image which can be expressed in non-image terms. Image analysis is often preceded by image processing.
Image arithmetic: although a digital image can be thought of as a 2-D array or "matrix" of values, mathematical equations involving images do not always follow the rules of matrix algebra. Thus, if i and j are the row and column of a particular pixel in an image A with intensity A(i,j), then the sum of images A and B, A+B is an image C where::
C(i,j) = A(i,j) + B(i,j)
for all pixels. However the product of the two images A and B, A*B is an image C where:-
C(i,j) = A(i,j) * B(i,j)
for all pixels, rather than the formal definition of a matrix product.
Although storage of intensities in "integer" format, with discrete values, is normally adequate for representing the original image, intermediate values during calculation may fall outside the range even though the final result is still within range (e.g. during a Fourier transform). Care has to be taken with integer arithmetic to preserve precision through an arithmetic operation. In these cases floating-point arithmetic may be used.
Image processing: operations designed to make an image more useful. Image processing is often regarded as embracing image analysis, but in this course we tend to regard image processing as the set of methods used to enhance the image prior to image analysis.
Intensity: a term which is used rather loosely in this context, mainly to mean the number stored for a given pixel in the digitised image.
JPEG: a standard for still image compression. Devised by the Joint Photographic Experts Group and sanctioned by the International Standards Organisation (ISO) and the CCITT. There are several implementations of the JPEG standard, some proprietary. JPEG, also known as JFIF takes areas of 8 x 8 pixels and compresses the information using the Discrete Cosine Transform. Parts of the resultant data may be sacrificed if loss in fidelity may be tolerated, leading to a high degree of compression. Other forms of compression may then be applied to present the data in a still more compact form. With high compression the 8 x 8 pixel blocks may become apparent in an objectionable manner. This effect is sometimes described colloquially as ‘blockiness’: the higher the compression the more prominent the ‘blockiness’.
Kalman filter: a recursive procedure which enables estimation of signals to be determined from successive measurements in time. In the context of image acquisition, this normally refers to the technique of using a single frame store to accumulate an image which is close to the true average of all acquired frames since the store was last initialised. For a given pixel, the true average over all frames often represents the best estimate of true intensity for that pixel.
Lab Colour: L*a*b* is a color model developed by the Centre Internationale d´Eclairage (CIE). These standards are internationally accepted standards for colorimetric measurements. The Lab model, like other CIE colour models, defines colour values mathematically, in a device independent manner. Lab colour is consistent, regardless of the device producing the colour.
Look-up table: a means whereby the digitised video signal may be altered to produce a more readily interpreted display. Instead of displaying an image so that the brightness of each pixel is proportional to its numerical value, the values in the stored digital image can be converted on display to a different value using the look-up table. A grey image can therefore be displayed as a negative or part of the range of grey values expanded without changing the stored data. By giving different tables for different colours the original grey image can be displayed in false colour. A look-up table can also be applied to the input from the TV camera.
Lossless compression: image and data-compression applications and algorithms, such as Huffman Encoding, that reduce the number of bits a picture would normally take up without sacrificaing any fidelity.
Lossy compression: methods of image compression, such as JPEG, that reduce the size of an image by sacrificing some pictorial information.
Luminance: the black and white or brightness portion of a video signal.
Mapping: the mathematical conversion of one set of numbers into a different set based upon some transformation.
Monochrome image: an image displayed in shades of a single colour, normally grey.
Neighbourhood (or local) operations: operations on an image using the neighbourhood of each pixel to calculate a new value for that pixel. Typically a 3 x 3 or 5 x 5 group of pixels is used to "smooth" an image or enhance some aspect of the image, such as the edge of a feature.
# Object: in a binary image, a region in which all the pixels are connected (according the the connectivity rules that apply in the image analysis system) , and which is surrounded by pixels of the other type.
Object-measurements: measurements which relate to the individual objects in the image, and which can be combined with others on an object-by-object basis to give other information: for example, roundness or aspect ratio.
Overlay: superimposition of a binary image, graphics or text over a grey image, using colour or good contrast to differentiate between the two images.
Pointset: a set of connected pixels which can be represented in an efficient way, allowing very fast access to the data they represent.
Parallax: the difference in position of the same feature between two images recorded under different conditions (e.g. sample tilt).
Pixel (or picture element): normally refers to one of the grid points on the 2-D grid or the corresponding element in the 2-D array of intensity values representing the digitised image. 640 x 480 is the pixel resolution of most VGA monitors. Pixels are typically square in computers, but may be rectangular in video applications.
Pixellation: The stair-stepped appearance of a curved or angled line in digital imaging. The smaller the pixels, and the greater their number, the less apparent the "pixellation" of the image. Also known colloquially as the "jaggies".
Plug-In: a program architecture was first popularized by Adobe Photoshop and is now a de facto standard for all major imaging programs. Compared with Twain it allows more flexibility in design so that acquisition, export and other specific tasks can be performed within a software application. This is the preferred choice of operation in the Macintosh computers. Plug-In ideology has spread to other applications like Netscape Navigator, Macromedia Director, and so on. Not all plug-ins work with all products and specific interfaces are required for different types of software. Adobe’s software has become a de facto standard for image editing software and graphic illustration software.
Pointset: a set of connected pixels which can be used to describe that feature, e.g. the boundary of a feature.
Precision: the extent to which a result can be reproduced in successive experiments as opposed to the difference between the result and the "true" value.
RAM/ROM: Random access memory, and Read-only memory. Memory is a vital element of any computing or image processing system, in which program information, image and other data can be stored. Any of the contents of RAM or ROM can be freely accessed at high speed, in contrast to serial storage devices like magnetic tape (and, to some extent, magnetic disk) in which the data stored can only be accessed in a fixed order. RAM can be read from and written to, while ROM (Read-only memory) can only be read from. ROMs are usually programmed by the manufacturer of the system, and their content is permanent and cannot normally be changed by the user.
SRAM: Static RAM, is the fastest but most expensive type of RAM, often found in framestores, some Printers, and in PCMCIA Type I Cards. Compare with DRAM (dynamic RAM), which is slower and cheaper, and is most often seen as the expandable RAM used in the computer for memory.
Remote sensing: the acquisition and interpretation of satellite and aerial images, seismographic and other related responses, often for geographical or land-use studies.
Resolution: the ability to discriminate closely spaced objects in an image. The resolution of an image analysis system may be governed by electronic, optical or other considerations. The density of the sampling points affects the amount of detail visible in an image.
RGB: an additive colour model that forms colours by mixing various ratios of red green and blue. Computer monitors and digital cameras use these primary colours to create all the hues seen on the monitor and saved in files.
Saturation: designates the purity of a colour or how much the colour is diluted by white. Red is a highly saturated colour. Pink has the same hue but a lower saturation.
S/N ratio (or signal to noise ratio): the ratio between the level of signal (or significant information) and the level of noise. Often used rather loosely to indicate the extent of information of interest as opposed to spurious detail in an image. In this context, noise is predominantly the fluctuations due to counting statistics.
Screen widths: an imaginary screen can be defined for display of a scanned image where at a given magnification.
Width of field on specimen = Screen width x Magnification.
Segmentation: the process of separating an image into the various features, discriminating those parts of an image which are of interest from those which are not (the 'background'). The simplest type of segmentation is thresholding.
Shape factor: a number derived from two or more measurements which indicates something particular about the shape of the feature. There are many different shape factors, e.g. Maximum projection / Minimum projection will be large for needle-like features but near unity for circular objects. Measurements are combined to form a factor which is dimensionless and thus independent of the size of feature, for example Area / (Maximum projection).
Smoothing: a smoothed image is one where the intensity at a pixel has been replaced by a value based on the pixel intensities in the immediate neighbourhood. This can be a simple average over a 3 x 3 area or a weighted average where smoothing coefficients are used (often arbitrarily!) to weight according to the distance from the central pixel (e.g. "Gaussian" smoothing). The median of the neighbourhood can also be used. Smoothing changes spiky statistical fluctuations into blobby artefacts and can only be used reliably where an independent measure of noise is available.
Spatial frequency: the rate of change of pixel intensity in an image. Usually regarded as a two-dimensional quantity, with both horizontal and vertical components.
Stereology: the study and measurement of the average properties of a three-dimensional structure from measurements made on two-dimensional sections. Depending on the shape and distribution of features on a section it may be possible to calculate the properties of the original specimen, e.g. Volume fraction of a component = Area fraction of that component measured on sections. Surface area estimation from linear measurements is not so easy.
Thresholding: the simplest process for converting a grey scale image to a binary image by comparing each pixel value to a threshold value. In one implementation those pixels exceeding the threshold become white, while the remainder become black.
Threshold: a grey level value which can be used to distinguish objects or regions of interest from the background. In many classes of image, a single threshold value may not be sufficient for satisfactory segmentation.
TIFF: Tagged Image File Format. A bit map file format for describing and storing colour and grey scale images.
TV scan rate: in conventional (CCIR - European standard) TV images, the scanning beam traverses the full width of the field of view every 64 m sec, and covers the even-numbered lines within the field in 20 msec, and the odd lines in a further 20 msec. A complete image frame consists of interlaced even and odd lines (referred to as the even and odd fields). Hence, it takes 40 msec to build an entire image frame.
Twain: An interface for image acquisition developed by a consortium of software developers as a standard for communications between scanners, imaging devices (and more recently digital cameras) and the computer. Twain provides for easy import or acquisition of images from a range of devices into software applications that support the standard. This is a widely used interface on the MS Windows platform.
WYSIWYG: an acronym which stands for "what you see is what you get". This refers to the possibility with modern software of viewing on the screen accurate representations of images which can be printed out. The term came into vogue with the development of word processing software, but is often used in the context of packages for DTP or image manipulation. Pronounced "WizzyWig".# source https://depts.washington.edu/bicg/documents/BE244_Glossary.pdf
artifact: artificial defect in the image, due to problems in sensing equipment (scratches in Xray digitized films), or during examinations (patient motion), ….
binary image: image where pixels have only two values, generally 0 and 1
brightness: The gray level value of a pixel within an image that corresponds to energy intensity. The larger the gray level value, the greater the brightness.
clustering: concept of grouping data in classes based upon the similarity of the data
compression: removal of any redundant data that may be present within the image, to reduce amount of data to manipulate or store.
contrast: the amount of gray level variation within an image
digitizer: electronic circuit that converts analog or continuous signals into discrete or digital data
dilation: a morphological operation that enlarges the geometrical size of objects within an image
discrete convolution: process where 2 images are combined using a shift, multiply and add operation.
Typically one image is substantially smaller than the other and is called the “mask” or “window”. Masks can be designed to perform a wide range of filtering functions.
enhancement: algorithms and processes that improve an image based on subjective measures. The goal is to accentuate certain image features for subsequent analysis or for display.
erosion: morphological operation that reduces the geometrical size of objects within an image
feature: any of the properties that are characteristic of an image, from which a description, interpretation or understanding of the scene can be provided by a machine.
graylevel: value of gray from a black and white (monochrome) image
grayscale: range of gray shades, or gray levels corresponding to pixel values that a monochrome image incorporates
histogram: distribution of pixel graylevel values. A graph of number of pixels at each graylevel possible in an image.
mask: refers to a small image used to specify the area of operation to take place on a larger image in an algorithm
matrix: image representation using MxN matrix is a 90° clockwise rotation of the conventional twodimensional Cartesian coordinate representation.# mean: the average of a set of data values (mean of {3,5,6,7,4,3,2,2} is 3+5+6+7+4+3+2+2/8=4
median: the middle value of a set of ordered data values (median of {3,5,6,7,4,3,2,2} is {2 2 3 3 | 4 5 6 7}=3.5
morphology: originally comes from the study of forms, of plants or animals. Image morphology represents study of topology or structure of objects from their images. Morphological processing refers to certain operations where an object is “hit” with a structuring element and thereby reduced to a more revealing shape.
noise: degradation of image due to equipment (i.e. sensor, camera misfocus), type of modality, motion, turbulence, …
object boundaries: linked edges that characterize the shape of an object
opening: morphological operation that is used to smooth the geometrical shape of objects within an image. Opening is a morphological erosion followed by a morphological dilation operation.
outline: the contour of objects within an image
patterns: a reliable sample of observable characteristics of an image
pixel: slang for picture element, the smallest element if an image
profile: imaging function that plots or displays pixel data along a line within an image to yield a cross section of values
quantization: range of values that a pixel can represent
region of interest (ROI): zone under study within the image (2D or 3D)
representation: characterization of the quantity that each pixel represents. For example an image could represent the absorption characteristics of the body tissue (Xray imaging) or the temperature profile of a region (infrared imaging)
resolution: smallest feature (spatial) or graylevel value (quantization) that an image system can resolve.
restoration: algorithms or processes that attempt to remove a degradation (noise, blurring, and defocusing effects) based on an objective criterion
sampling: used to describe spatial resolution of an image
segmentation: separation of different objects in the image (for example by extracting their boundaries).
slice: 2D image often described as part of a 3D volume
skeletonization: algorithm used to find the central axis (skeleton) of an image object
structuring set: set of pixels used to describe the structuring function used in the morphological erosion and dilation
texture: structural patterns of surfaces of objects such as wood, grain, sand, grass, cloth. The term texture generally refers to repetition of basic texture elements called texels. A texel contains several pixels whose placement could be periodic or random. Texture may be coarse, fine , smooth, granulated, regular, irregular, linear, etc…
threshold: a value used to segment the graylevel values of an image into two different regions. Also called the binarization of an image.
voxel: 3D pixel
zoom: process by which an image is magnified by a computer algorithm.# source: https://www.photoreview.com.au/information/digital-imaging-glossary/#:~:text=Exposure%3A%20A%20term%20used%20to,according%20to%20a%20selected%20pattern.
AE and AF Locks: Button controls on a camera that allow photographers to lock the exposure on a different part of the subject from the point of focus – or vice versa. In most cameras, pressing the shutter button halfway down locks both the AE (auto exposure) and AF (autofocus) settings.
Ambient Light: The light that exists in a specific situation without augmentation with flash or studio lights. Also known as ‘available light’.
Aperture: The opening in the iris diaphragm of a lens that allows light to pass through the lens to the image sensor.
Aperture-priority: Usually denoted by the A (or Av) setting on a camera’s mode dial, this shooting mode allows the photographer to set a specific aperture value while the camera will adjust the shutter speed automatically to ensure a correct exposure. The main purpose of this shooting mode is to control depth-of-field.
APS-C: A term originally developed for the ‘Advanced Photo System’ film format but now used to define a digital imaging sensor size that measures between 21.5 x 14.4 mm and 23.7 x 15.7 mm in area.
Archiving: Preserving digital images in a way that is independent of where these records are kept. Image archives can consist of prints or copies on optical disk or hard disk drive.
Artefacts: Undesirable visual defects produced by digital imaging systems. They can be generated by either input or output devices and include noise, colour casts, distortions and lost information. All degrade image quality.
Aspect Ratio: The relationship between the horizontal and vertical dimensions of an image. The horizontal dimension is normally quoted first. A 35mm film frame has an aspect ratio of 3:2, as do most DSLR cameras. Images from Four Thirds System DSLRs and compact digicams have a 4:3 aspect ratio. Many digital cameras and camcorders also offer a ‘widescreen’ format with a 16:9 aspect ratio.
Autofocus (AF): A camera control that focuses the lens on the subject. Two types of AF are in common use, active infrared (IR) and passive contrast-based. The former fires a beam of infrared light at the subject and calculates its distance on the basis of the return reflection; while the latter evaluates distance on the basis of image contrast (close subjects have higher contrast than their background). Many cameras include servo-AF systems that can focus on a moving subject. This is also known as ‘focus tracking’.
Barrel Distortion: A type of image distortion that expands the central dimensions of the picture without affecting the periphery. It is most common in wide-angle lenses.
Bit: Short for ‘binary digit’, a bit is the smallest piece of information that can be handled by a computer and has a value of 0 or 1.
Bit Depth: The number of bits (binary digits) used to specify the brightness or colour range of each pixel in an image sensor. JPEG images are always recorded with 8-bit depth, which can record 256 (28) levels of red, green and blue. Cameras that support raw file capture offer higher bit depths, usually ranging from 12 to16 bits.
Bitmap: A file format that records image data as individual pixels. Denoted by the .bmp extension.
Blooming: The halo effect that occurs at borders between dark and light image tones due to an overflow of electrical charge that is generated by excessive light exposure on part or all of the image sensor.
Bracketing: An exposure technique that involves taking a series of shots with slightly different camera settings from those determined by the camera’s automatic measurements. Most cameras provide bracketing controls for exposure and some also provide white balance and focus bracketing.
Buffer Memory: A special RAM storage area in a digital camera’s memory system where image data is held while it awaits processing and transfer to the camera’s memory card. A large buffer memory is required to support high-speed continuous shooting, especially at high image resolution.
Burst (Continuous) Shooting: A function that allows a camera to record a number of sequential shots in rapid succession. The number of frames that can be captured depends on the image resolution and the size of the buffer memory.
Centre-weighted Average Metering: An exposure metering pattern that integrates readings from all over the field of view, placing more emphasis on the centre of the field.
CCD (Charge-Coupled Device): A light-sensitive array of silicon cells that is commonly used for digital camera image sensors. It generates electrical current in proportion to light input and allows the simultaneous capture of many pixels with one brief exposure.
CMOS (Complementary Metal-Oxide Semiconductor): The alternative sensor array to CCD. CMOS sensors are cheaper to manufacture and use less power. Most digital SLR cameras have CMOS image sensors, while the majority of digicams use CCD technology.
Colour Filter Array: A mask, made of thin layers of dye that is applied over a digital camera sensor to enable it to record colour information. The individual colour patches filter out all but the chosen colour for that photosite and software interpolation is used to create a colour value for the resulting pixel based on surrounding pixel values. The most common filter pattern is the Bayer array, which uses alternating rows of red/green and green/blue patches (GRGB).
Colour: The value produced by combining luminance (brightness) and chrominance (colour) signals.
Colour Management: Setting up a combination of software and hardware devices to produce accurate colour reproduction through all stages of a digital imaging system – from capture to output.
Colour Space: A geometrical system used to describe a range of colours. Adobe RGB (1998) and sRGB are the most commonly used colour spaces in digital imaging.
CompactFlash (CF): A type of camera memory card that is commonly used in DSLR cameras. CF cards measure 43 x 36 mm in area and most are 3.3 mm thick. They come in capacities up to 64GB.
Compression: A mathematical processing system used to reduce the size of digital data files. Two types of compression are common in digital imaging: lossy (which sacrifices some data in order to obtain small files) and lossless (which involves little or no information loss).
Contrast: The difference between the lightest and darkest tones in an image. High-contrast images contain few steps between the lightest and darkest parts of the image, while low-contrast images contain many tonal gradations.
Crop: A manual or digital process that cuts away unwanted parts of an image.
Depth-of-Field: The area in a scene that appears acceptable sharp in a photographic image. Depth-of-field is controlled by the lens aperture. It is greatest with distant subjects, wide-angle lenses and small lens apertures and least with close subjects, telephoto lenses and large lens apertures. Some DSLR cameras have a dept-of-field preview button that temporarily closes the iris diaphragm so photographers can see the depth-of-field they will get in a shot.
Digital SLR (DSLR): A digital camera in which the subject is viewed through the same lens as the picture is taken with. A mirror is raised when the shutter button is pressed, allowing light to reach the image sensor. Most DSLR cameras use interchangeable lenses.
DPI (Dots Per Inch): The most commonly used unit of measurement for describing the resolution of digital image files for printing or scanning.
DPOF (Digital Print Order Format): Most digital cameras are compatible with the Digital Print Order Format (DPOF), a special type of metadata that lets users specify the photos they want printed by using the camera’s menu system. The DPOF file is written to the camera’s removable media, from which it can be read and executed by printing services and computer-based applications.
Dye-sublimation: A printing technology that uses dye-transfer to produce coloured prints. Most printers are restricted to snapshot-sized output.
Dynamic Range: The measurable difference between the brightest highlight and darkest shadow area in an image that can be reproduced by an imaging system.
Effective Pixels: The number of pixels that are actually used to capture the image (as distinct from the total pixel count for the sensor). The remaining pixels (the difference between total and effective pixels) are used to provide a ‘dark current reading’ so the camera has a black reference point. The number of unused pixels is at the camera manufacturer’s discretion, which is why effective pixel count is the only reliable guide to the camera’s resolution potential.
Exposure: A term used to describe the combination of lens aperture and shutter speed that delivers a pre-determined amount of light to the image sensor. All cameras include exposure meters, which measure the tones in the subject according to a selected pattern.
Exposure Compensation: A camera setting that allows photographers to over-ride the settings used by the camera to reduce or increase the overall exposure value. The control is indicated by a +/- icon, either on a button or in a menu.
Exposure Value (EV): A number determined by the brightness of the subject and the sensitivity selected for the recording medium, it is larger for bright subjects and smaller for dark ones. When the amount of light doubles, the EV increases by 1, making the value equivalent to one stop of exposure.
Fast lenses: Lenses with large maximum apertures – typically f/1.8 to f/2.8. Because they require more – and better quality – glass, fast lenses command premium prices.
File Format: The way in which digital information is saved by a software application. The most commonly used file formats for digital imaging are JPEG, TIFF and BMP (bitmap). Raw files are proprietary and, often, unique to each camera. Special software is required to decode raw files.
Filters: Add-on accessories that are used to change the appearance of digital images as they are recorded.
Flare: An imaging problem cause by light scatter within a lens. It is commonly seen in photographs of backlit subjects and may show up as bright or coloured spots on the subject or an overall reduction in contrast. Flare is reduced by coating the lens elements and using a lens hood to prevent stray light from entering the lens.
Flash Synchronisation: A control that ensures the flash is fired when the camera’s shutter is open. Modern cameras often offer several flash synch settings; typically slow synch, which engages a slow shutter speed to allow background details to be recorded, first-curtain synch, which fires the flash just after the shutter opnes and rear-curtain synch, which fires the flash just before the shutter closes.
Four Thirds System: A digital SLR system developed by Olympus, Kodak and Panasonic that centres on an image sensor size of 18.0 x 13.5 mm and uses a special, non-propriteary lens mount.
‘Full Frame’ Sensor: An image sensor measuring 36 x 24 mm in area – which has the same surface area as a 35mm film frame.
Gamma: The technical term used to describe image contrast, it refers to the slope of the line that represents image output values versus image input values. It is applicable to both film-based and digital images.
Gamut: The range of colours that an image contains or an output device can reproduce.
Graduated Filters: Graduated filters are filters with variable light transmission. Typically half of the filter area is darker or a different colour while the rest is clear. They are used to darken overly-bright skies to ensure scenic shots have a natural balance between sky and land tones.
Highlight & Shadow Alerts: Playback settings that allow images to be displayed with blinking highlights and/or shadows so photographers can see whether shots have been correctly exposed.
Histogram: A graphical display that shows the distribution of tones within an image. The horizontal co-ordinate represents the possible pixel values from black to white, while the vertical co-ordinate shows the number of pixels in the image at each value.
Hue: The component of colour that relates to a specific wavelength or CIE co-ordinates.
Image Noise: A reduction in image quality that is usually seen as graininess and/or tiny white and coloured dots. It is caused by random fluctuations in the digital signal and associated with high ISO sensitivity settings and long exposure times.
Image Processor: The computer chip in a digital camera that converts the analogue signal from the image sensor into a digital picture.
Image Sensor: The element in a digital camera that records the digital image. Two types are popular: Charge-Coupled Devices (CCD) and Complementary Metal-Oxide Semiconductor (CMOS). CCDs are universally used in compact digicams while CMOS sensors are more common in DSLR cameras.
Image Stabilisation: A system for reducing the effect of camera shake. Two technologies are in common use, one compensating by moving elements in the lens and the by moving the sensor. The former is more effective.
Inkjet: A type of printer that applies microscopic ink droplets to paper to form images, graphics or text.
Internal Focusing (IF): A system for focusing a lens by moving internal elements. It allows the lens to remain the same length and its barrel does not rotate while focusing occurs, allowing angle-critical accessories like polarisers and graduated filters to be used.
Interpolation: A mathematical re-sampling technique that is used to alter the size of an image file by creating or removing pixels on the basis of existing pixel values. Some quality is sacrificed as a result of the interpolation process, particularly if files are made larger.
Iris diaphragm: The structure controlling the aperture in a camera’s lens. The ratio between the diameter of this aperture and the focal length of the lens is given in an f/number.
ISO: The International Standards Organisation’s system for defining sensor sensitivity. The system works by doubling. ISO 200 is double the sensitivity of ISO 100 and half the sensitivity of ISO 400.
JPEG: The image file format developed by the Joint Photographic Experts Group and denoted by the ‘.jpg’ extension.
Kelvin (K): Colour ‘temperature’ is measured on a Kelvin scale, in which colours are denoted by the temperatures at which a heated black-body radiator matches the colour of the light source. This system allows precise colour values to be specified.
Lag: A term denoting delay after an action has been initiated. The most common lag times in digital imaging include shutter lag, autofocus (AF) lag and processing lag. Shutter lag describes the time taken for the camera to capture the shot after the shutter release has been pressed. AF lag defines the time it takes the camera to autofocus and processing lag describes the time images take to be processed and transferred to the memory card so the next image can be captured.
Landscape: A camera mode that sets the lens focus to near infinity, selects a small lens aperture and cancels the flash. For printing, the term defines a page orientation that is wider than it is high.
LCD (Liquid Crystal Display): LCD screens are used in digital cameras to preview and review shots. In some cameras they replace the optical viewfinder. Most also provide access to the camera controls via a set of menus, which are called up on screen and selected by pressing a button. Some cameras have separate LCD screens that display status information, such as frame counts, camera settings and battery power.
Lens: The optical device consisting of several glass elements which transmits and refracts light to produce the image that is recorded by a camera’s sensor. DSLR cameras use interchangeable lenses.
Live View: A function on all compact digicams and many recent DSLR cameras that allows the LCD monitor to be used for composing photographs.
Manual: The Manual (M) setting on a camera’s mode dial gives the photographer full control over the lens aperture and shutter speed settings.
Megapixels: A term used to describe one million pixels. It is used to define the number of pixels in a digital image and also (erroneously) to express the number of photosites in the image sensors in digital cameras.
Metadata: Structured data, stored with digital image files, which explains, locates, describes or otherwise makes using the original primary data more effective or efficient. Two types of metadata are important for digital camera users: the Exif standard and the Digital Print Order Format (DPOF) standard.
Monochrome: Refers to an image that is all one colour, typically black and white (with intermediate grey tones) or sepia. When images are recorded in monochrome, colour information is discarded.
Multi-pattern Metering: An exposure metering pattern that divides the subject area into five or more segments and individually evaluates the light levels within each segment. Exposure settings are determined by balancing the readings from each segment.
Noise: A random pattern of unwanted pixels that degrades the quality of image files.
Optical Zoom: The maximum zoom range achievable with the camera’s lens. Image quality is fully maintained.
Orientation: The direction in which a page is printed: landscape is printed horizontally, while portrait is printed vertically.
Photosite: The light-sensitive cell on a digital image sensor, it records one intensity and one colour value. Information from several photosites is required to create a pixel in the image.
Pincushion Distortion: An image aberration that compresses the centre of the field.
Pixel: Short for ‘picture element’, this term describes the basic component of a digital image. Individual pixels are generally square and carry one value for colour, luminance and intensity. Millions of pixels are required to produce a digital image that approaches photographic quality.
Playback Zoom: A camera function that enables photographers to enlarge part of an image during playback to check focusing and exposure levels.
Polarisers or Polarising Filters: Polarising filters are used to reduce the effects of scattered light and, thereby, brighten colours and allow blue skies to be reproduced with a natural appearance. They can also reduce the effect of specular reflections off water or other shiny surfaces. Two types are available: linear and circular. Circular polarisers are recommended for photography.
PPI (Pixels Per Inch): Often used interchangeably with DPI to describe the resolution of a digital image.
Prime Lens: A lens that covers only one focal length.
Pro-sumer: Between professional and consumer (usually referring to camera equipment).
Raw Data: Digital information that has not been processed or formatted.
Raw Files: Raw files contain the image data as it is captured by the camera’s sensor with only minimal processing applied. Many high-end digital cameras provide a raw capture option, most using proprietary file formats that require special software to decode. Because they are un-processed, raw files are effectively ‘digital negatives’.
Resolution: The ability to reproduce fine detail – or the amount of detail in the image.
RGB: A colour model based on the red, green and blue components in the output, it is typically used for images that will be displayed on monitors.
Saturation: The intensity of a hue. Pastels have low saturation, while bright colours are highly-saturated.
Secure Digital (SD): A type of camera memory card that is used in some DSLR cameras. SD cards measure 32 x 24 x 2.1 mm and come in capacities up to 32GB. A high-capacity version, SDHC (Secure Digital High Capacity) was launched in 2006 and offers faster data transfer speeds.
Sharpening: An image enhancement technique that gives more distinct edges to subject areas, lines and tones in a digital image. Sharpening can be applied in the camera or in editing software.
Sharpening Artefacts: Defects introduced by in-camera sharpening systems. These generally appear as white or black halos around high-contrast areas in the subject and can sometimes be minimised by turning off the auto sharpening function in the camera.
Shutter Priority: Usually denoted by the S (or Tv – for time value) setting on a camera’s mode dial, this shooting mode allows the photographer to set a specific shutter speed while the camera will adjust the lens aperture automatically to ensure a correct exposure. The main purpose of this shooting mode is to control the ways in which motion is depicted. Fast shutter speeds are used to ‘freeze’ movement, while slow shutter speeds record movement as a blur.
Spot Metering: An exposure metering pattern that takes a single reading from a small section of the field of view.
Telephoto: A term used for lenses with focal lengths greater than 70mm.
Thumbnail: A reduced-size, low-resolution version of a digital image, used mainly for sorting and retrieving image files.
TIFF (Tagged Image File Format): An image file format based on bitmapping that involves little or no data compression. Denoted by the .tif extension.
Tungsten Lighting: Light produced by either photofloods or domestic illumination, it has a Kelvin value of 3200 and is warmer than normal daylight.
USB (Universal Serial Bus): The most common way of connecting a peripheral device to a computer, USB offers ‘hot’ plug and play (you don’t need to power-down the PC). The latest version USB 2.0 is significantly faster than the original USB 1.0 and USB 2.0 Hi-Speed is even faster.
VGA (Video Graphics Array): A video monitor with 640 x 480 pixel resolution. Also applied to 640 x 480 pixel images.
White Balance: The control on a digital camera used to adjust the colour balance of the image to make shots look natural under a variety of different lighting conditions. Most cameras have pre-sets for tungsten and fluorescent room lighting plus daylight and open shade. A few also include a flash setting. Virtually all digital cameras have an auto white balance setting.
Zoom: A camera or software control that causes the image – or part of it – to appear larger (zooming in) or smaller (zooming out).
Zoom lens: A lens that covers a range of focal lengths. Zoom lenses are usually several stops slower than prime lenses, particularly at longer focal lengths.